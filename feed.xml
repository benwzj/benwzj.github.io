<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://benwzj.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://benwzj.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-21T13:22:40+00:00</updated><id>https://benwzj.github.io/feed.xml</id><title type="html">BEN WEN</title><subtitle>A website to show the world of Ben Wen </subtitle><entry><title type="html">Pandas main points</title><link href="https://benwzj.github.io/blog/2025/pandas/" rel="alternate" type="text/html" title="Pandas main points"/><published>2025-05-18T00:00:00+00:00</published><updated>2025-05-18T00:00:00+00:00</updated><id>https://benwzj.github.io/blog/2025/pandas</id><content type="html" xml:base="https://benwzj.github.io/blog/2025/pandas/"><![CDATA[<p>Pandas is a powerful Python library for data manipulation and analysis.</p> <h2 id="core-data-structures">Core Data Structures</h2> <h3 id="series">Series</h3> <p>A one-dimensional labeled array holding data of any type such as integers, strings, Python objects etc.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</code></pre></div></div> <h3 id="dataframe">DataFrame</h3> <p>A two-dimensional data structure that holds data like a two-dimension array or a table with rows and columns. Think of it like a spreadsheet or SQL table.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">Name</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">Alice</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Bob</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Charlie</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">28</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">City</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">New York</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">London</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Paris</span><span class="sh">'</span><span class="p">]}</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div> <h2 id="reading-and-writing-data">Reading and Writing Data</h2> <p>Pandas can read and write data from various formats like CSV, Excel, JSON, SQL databases, and more.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Reading from CSV
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">data.csv</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Writing to CSV
</span><span class="n">df</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">output.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>  <span class="c1"># index=False prevents writing row indices
</span>
<span class="c1"># Other formats:
# pd.read_excel('data.xlsx')
# pd.read_json('data.json')
# ...
</span></code></pre></div></div> <h2 id="accessing-data">Accessing Data:</h2> <h3 id="columns">Columns</h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">names</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">Name</span><span class="sh">'</span><span class="p">]</span>  <span class="c1"># Access the 'Name' column as a Series
</span><span class="n">ages</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">Age</span>       <span class="c1"># Alternative way to access a column
</span></code></pre></div></div> <h3 id="rows">Rows</h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">first_row</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Access the first row by label
</span><span class="n">second_row</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># Access the second row by integer position
</span></code></pre></div></div> <h3 id="slicing">Slicing</h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">subset</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>   <span class="c1"># Rows 2 and 3
</span></code></pre></div></div> <h2 id="data-manipulation">Data Manipulation:</h2> <h3 id="filtering">Filtering:</h3> <p><code class="language-plaintext highlighter-rouge">young_people = df[df['Age'] &lt; 30]</code></p> <h3 id="sorting">Sorting:</h3> <p><code class="language-plaintext highlighter-rouge">df_sorted = df.sort_values(by='Age', ascending=False)</code></p> <h3 id="adding-columns">Adding Columns:</h3> <p><code class="language-plaintext highlighter-rouge">df['NewColumn'] = df['Age'] * 2</code></p> <h3 id="applying-functions">Applying Functions:</h3> <p><code class="language-plaintext highlighter-rouge">df['NameLength'] = df['Name'].apply(len)</code></p> <h3 id="grouping">Grouping:</h3> <p><code class="language-plaintext highlighter-rouge">grouped = df.groupby('City')['Age'].mean()</code></p> <h2 id="handling-missing-data">Handling Missing Data:</h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">dropna</span><span class="p">()</span>       <span class="c1"># Remove rows with missing values
</span><span class="n">df</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>      <span class="c1"># Fill missing values with 0
</span></code></pre></div></div> <h2 id="data-analysis">Data Analysis:</h2> <p>Pandas provides various functions for data analysis, including statistical summaries, aggregations, and more.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">describe</span><span class="p">()</span>   <span class="c1"># Statistical summary
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">()</span> <span class="c1"># Mean age
</span></code></pre></div></div> <h2 id="combining-dataframes">Combining DataFrames:</h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">merged_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">KeyColumn</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># Merge two DataFrames based on a common column
</span><span class="n">concatenated_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">])</span>        <span class="c1"># Concatenate DataFrames
</span></code></pre></div></div> <h2 id="references">References</h2> <ul> <li><a href="https://pandas.pydata.org/docs">Pandas website</a></li> </ul>]]></content><author><name></name></author><category term="Python"/><category term="ML"/><category term="Python"/><summary type="html"><![CDATA[Pandas is a powerful Python library for data manipulation and analysis.]]></summary></entry><entry><title type="html">Embedding</title><link href="https://benwzj.github.io/blog/2025/embedding/" rel="alternate" type="text/html" title="Embedding"/><published>2025-05-06T00:00:00+00:00</published><updated>2025-05-06T00:00:00+00:00</updated><id>https://benwzj.github.io/blog/2025/embedding</id><content type="html" xml:base="https://benwzj.github.io/blog/2025/embedding/"><![CDATA[<p>Embeddings is the basic key point to understand Machine Learning. And it is Machine Learning’s Most Useful Multitool.</p> <p>Embeddings are a powerful technique in AI, enabling machines to understand and work with complex data in a more meaningful way. They play a crucial role in various applications, from natural language processing to computer vision and recommendation systems.</p> <p>In machine learning, an embedding is a way of representing data as points in n-dimensional space so that similar data points cluster together.</p> <h2 id="what-are-embeddings">What are Embeddings</h2> <p>Abstractively, embeddings allow us to find similar data points. The machine can understand things because of embedding. Realistically, embeddings store semantically meaning in arrays of number.</p> <p>What kinds of things can be embedded? All The Things! Text, Images, Videos, Music.</p> <p>Embeddings are typically learned from large datasets using machine learning techniques.</p> <h3 id="understand-embeddings">Understand Embeddings</h3> <p>When talk about embeddings, i though it is just lots of array of numbers which telling about the things. But how to define this dimensions? what algorithm to operate this dimensions? Embedding should be a whole system, it including the start and the end. it include algorithms, data training, etc. It can embed your input into arrays, it can understand those arrays, it can capture semantic relationships, and it can inference.</p> <p>So Creating embeddings starts with a large dataset. For example word embeddings, this is a text corpus. We define a model, often a <strong>shallow neural network</strong> like in Word2Vec. Word2Vec’s skip-gram architecture, for instance, predicts surrounding context words given a target word. The model’s hidden layer weights become the word embeddings.</p> <h2 id="word-embedding">Word Embedding</h2> <p>Word embeddings are extremely useful in natural language processing. They can be used to find synonyms (“semantic similarity”), to do clustering, or as a preprocessing step for a more complicated nlp model.</p> <p>Example: Imagine the words “cat,” “dog,” and “car.” Their embeddings might look like this (simplified):</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat: [0.8, 0.2, 0.1]
dog: [0.7, 0.3, 0.2]
car: [0.1, 0.1, 0.9]
</code></pre></div></div> <p>Notice that “cat” and “dog” have similar embeddings, reflecting their semantic similarity, while “car” has a very different embedding.</p> <h2 id="pre-trained-models">Pre-trained Models</h2> <p>This pre-trained models also called Techniques which are used to create embeddings.</p> <p>A pre-trained embedding model is a model that has already been trained on a large dataset and can be used to generate embeddings for new data without further training (or with minimal fine-tuning). Think of it as a ready-to-use embedding generator.</p> <h3 id="some-famous-ones-are">Some famous ones are:</h3> <ul> <li>Word2Vec: a technique invented by Google in 2013. It Learns word embeddings by predicting surrounding words given a target word (or vice versa).</li> <li>GloVe (Global Vectors for Word Representation): Learns word embeddings by capturing global word co-occurrence statistics.</li> <li>FastText: An extension of Word2Vec that considers subword information, allowing it to generate embeddings for out-of-vocabulary words.</li> <li>Sentence Transformers: Generate embeddings for entire sentences or paragraphs.</li> <li>Graph Embeddings: Represent nodes in a graph as vectors.</li> </ul> <h3 id="how-to-use-a-pre-trained-embedding-model">How to use a pre-trained embedding model:</h3> <ul> <li>Choose a Model: Select a pre-trained model that suits your task and data. Popular choices include Word2Vec, GloVe, FastText, and sentence transformers like BERT. Consider factors like the size of the vocabulary, the dimensionality of the embeddings, and the type of data the model was trained on.</li> <li>Load the Model: Use a library like <code class="language-plaintext highlighter-rouge">Gensim</code> or <code class="language-plaintext highlighter-rouge">Hugging Face Transformers</code> to load the pre-trained model.</li> <li>Generate Embeddings: Input your data (e.g., words, sentences) into the loaded model to generate embeddings.</li> <li>Use the Embeddings: Use the generated embeddings as input features for your machine learning model or for other tasks like semantic search.</li> </ul> <p>Let’s say you want to build a sentiment analysis model. You could use pre-trained word embeddings from <strong>GloVe</strong>. You would load the GloVe model, then for each word in your input text, you would retrieve its corresponding pre-trained embedding vector. These vectors would then be used as input features for your sentiment analysis model.</p> <h3 id="example">Example</h3> <p>Using <code class="language-plaintext highlighter-rouge">google/universal-sentence-encoder</code> pre-trained model:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow_hub</span> <span class="k">as</span> <span class="n">hub</span>

<span class="n">embed</span> <span class="o">=</span> <span class="n">hub</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">https://tfhub.dev/google/universal-sentence-encoder/4</span><span class="sh">"</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="nf">embed</span><span class="p">([</span>
    <span class="sh">"</span><span class="s">The quick brown fox jumps over the lazy dog.</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">I am a sentence for which I would like to get its embedding</span><span class="sh">"</span><span class="p">])</span>

<span class="nf">print</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

<span class="c1"># Response looks like: [[0.001, 0.201, ...]]
# i.e., an array of vectors
</span></code></pre></div></div> <h2 id="what-is-word2vec-exactly">What is Word2vec exactly</h2> <p>Word2Vec is categorize as embedding model while BERT as a Language Model. Word2Vec provide methods, algorithms, neural network for embedding purpose. BERT can work to embedding, also can do much more various NLP tasks like generating contextualized word and sentence embeddings.</p> <h3 id="technique">Technique</h3> <p>You can say Word2vec is a technique. This technique is used for obtaining vector representations of words in natural language processing (NLP). These vectors capture information about the meaning of the word based on the surrounding words.</p> <h3 id="model">Model</h3> <p>You can say Word2vec is a group of models.<br/> Word2vec is composed of a group of related models that are used to produce word embeddings. These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words.</p> <h3 id="how-word2vec-approach">How Word2vec approach</h3> <p>Word2vec takes as its input a large corpus of text and produces a mapping of the set of words to a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a vector in the space. (Word2vec 将大量文本作为输入，并将词集映射到向量空间（通常有几百维），语料库中每个唯一的词都会在空间中分配一个向量。)</p> <p>Here are a little bit more detail: Word2vec can use either of two model architectures to produce these distributed representations of words: continuous bag of words (CBOW) or continuously sliding skip-gram. In both architectures, word2vec considers both individual words and a sliding context window as it iterates over the corpus.</p> <ul> <li>The CBOW can be viewed as a ‘fill in the blank’ task.</li> <li>In the continuous skip-gram architecture, the model uses the current word to predict the surrounding window of context words.</li> <li>CBOW is faster while skip-gram does a better job for infrequent words.</li> <li>A corpus is a sequence of words. Both CBOW and skip-gram are methods to learn one vector per word appearing in the corpus.</li> </ul> <h3 id="how-to-use-word2vec">How to use Word2Vec</h3> <p>Using Word2Vec involves two main steps: training the model (optional, as pre-trained models are available) and then using the trained model to generate word embeddings.</p> <h4 id="training-optional">Training (Optional)</h4> <p>This is optional, as pre-trained models are available. But you can still train it with your own data.</p> <h4 id="using-the-model">Using the Model</h4> <p>Load the Model:</p> <pre><code class="language-Python">from gensim.models import Word2Vec
model = Word2Vec.load("word2vec.model") # Or load a pre-trained model
</code></pre> <p>Get Word Embeddings:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vector</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">wv</span><span class="p">[</span><span class="sh">'</span><span class="s">cat</span><span class="sh">'</span><span class="p">]</span>  <span class="c1"># Get embedding for 'cat'
</span></code></pre></div></div> <p>Find Similar Words:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">similar_words</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">wv</span><span class="p">.</span><span class="nf">most_similar</span><span class="p">(</span><span class="sh">'</span><span class="s">cat</span><span class="sh">'</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># Find the 5 most similar words to 'cat'
</span></code></pre></div></div> <p>Perform Word Arithmetic (Analogy):</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">wv</span><span class="p">.</span><span class="nf">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">king</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">woman</span><span class="sh">'</span><span class="p">],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">man</span><span class="sh">'</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># king - man + woman = ? (queen)
</span></code></pre></div></div> <p>Use in Downstream Tasks: Use the embeddings as features in machine learning models for tasks like:</p> <ul> <li>Text Classification: Sentiment analysis, spam detection.</li> <li>Machine Translation: Encoding and decoding text in different languages.</li> <li>Information Retrieval: Semantic search.</li> <li>Recommendation Systems: Recommending similar items.</li> </ul> <h2 id="create-your-own-embeddings">Create Your Own Embeddings</h2> <p>Usually, when we are talking about Creating Our Own Embeddings, usually refer to fine-tuning some pre-trained model.</p> <p>Actually, you can creat one from scratch. Or saying train one. Here’s what you’ll need:</p> <ul> <li>Familiarity with Python and a deep learning framework like TensorFlow or PyTorch is <strong>essential</strong>.</li> <li>Data: A sufficiently large and relevant dataset is crucial.</li> <li>Algorithm: Choose an appropriate embedding algorithm. Word2Vec, GloVe, and FastText are good starting points for word embeddings.</li> <li>Computational Resources Access to a decent CPU, and ideally a GPU, will significantly speed up the process.</li> <li>Patience and Experimentation: requires patience and a willingness to experiment with different hyperparameters and architectures to achieve optimal results.</li> </ul> <p>Here are the highly simplified example:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Sample vocabulary and data
</span><span class="n">vocabulary</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">the</span><span class="sh">"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">"</span><span class="s">cat</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">"</span><span class="s">sat</span><span class="sh">"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">"</span><span class="s">on</span><span class="sh">"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="sh">"</span><span class="s">mat</span><span class="sh">"</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[[</span><span class="sh">"</span><span class="s">the</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">cat</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">sat</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">on</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">the</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">mat</span><span class="sh">"</span><span class="p">]]</span>

<span class="c1"># Hyperparameters
</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">window_size</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Initialize embeddings randomly
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>

<span class="c1"># Training loop (simplified)
</span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>  <span class="c1"># Example number of epochs
</span>    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)):</span>
            <span class="n">target_word</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">context_words</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="nf">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span> <span class="o">-</span> <span class="n">window_size</span><span class="p">):</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">sentence</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span><span class="nf">min</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">),</span> <span class="n">i</span> <span class="o">+</span> <span class="n">window_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>

            <span class="c1"># Simplified training logic (replace with actual gradient updates)
</span>            <span class="k">for</span> <span class="n">context_word</span> <span class="ow">in</span> <span class="n">context_words</span><span class="p">:</span>
                <span class="n">target_index</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="p">[</span><span class="n">target_word</span><span class="p">]</span>
                <span class="n">context_index</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="p">[</span><span class="n">context_word</span><span class="p">]</span>
                <span class="c1"># ... (Calculate gradients and update embeddings) ...
</span>
<span class="nf">print</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span> <span class="c1"># Your trained embeddings
</span></code></pre></div></div> <p>But A real implementation, it would involve things like</p> <ul> <li>A neural network: For predicting context words.</li> <li>Backpropagation: For calculating gradients.</li> <li>An optimization algorithm: Like SGD for updating embeddings.</li> </ul> <h2 id="faq">FAQ</h2> <ul> <li>When talking embedding, is it refer to an array of number?</li> <li>Who define the dimensions?</li> <li>Word2Vec is a pre-trained model or just a Techniques which difine demensions?</li> <li>How to create our own embedding model?</li> <li>What is the difference between text and image embedding?</li> <li>What is the relationship of Word2vec and Transformer?</li> <li>Can say BERT is a embedding model?</li> </ul>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="Embedding"/><category term="Vector"/><category term="ML"/><summary type="html"><![CDATA[Embeddings is the basic key point to understand Machine Learning. And it is Machine Learning’s Most Useful Multitool.]]></summary></entry><entry><title type="html">Core concepts behind ML</title><link href="https://benwzj.github.io/blog/2025/ml-core-concept/" rel="alternate" type="text/html" title="Core concepts behind ML"/><published>2025-05-06T00:00:00+00:00</published><updated>2025-05-06T00:00:00+00:00</updated><id>https://benwzj.github.io/blog/2025/ml-core-concept</id><content type="html" xml:base="https://benwzj.github.io/blog/2025/ml-core-concept/"><![CDATA[<p>ML is the <strong>process</strong> of training a piece of software, called a model, to make useful predictions or generate content (like text, images, audio, or video) from data.</p> <h2 id="types-of-ml-systems">Types of ML Systems</h2> <p>ML systems fall into one or more of the following categories based on how they learn to make predictions or generate content:</p> <ul> <li>Supervised learning</li> <li>Unsupervised learning</li> <li>Reinforcement learning</li> <li>Generative AI</li> </ul> <h3 id="supervised-learning">Supervised learning</h3> <p>Supervised learning models can make predictions after seeing lots of data with the correct answers and then discovering the connections between the elements in the data that produce the correct answers.</p> <p>Supervised ML models are trained using datasets with labeled examples.</p> <p>Two of the most common use cases for supervised learning are regression and classification.</p> <h4 id="regression">Regression</h4> <p>A regression model predicts <strong>a numeric value</strong>. For example, a weather model that predicts the amount of rain, in inches or millimeters, is a regression model.</p> <h4 id="classification">Classification</h4> <p>Classification models predict the likelihood that something belongs to a category.</p> <p>Classification models are divided into two groups: binary classification and multiclass classification.</p> <h3 id="unsupervised-learning">Unsupervised learning</h3> <p>Unsupervised learning models make predictions by being given data that does not contain any correct answers. An unsupervised learning model’s goal is to identify meaningful patterns among the data. In other words, the model has no hints on how to categorize each piece of data, but instead it must infer its own rules.</p> <p>A commonly used unsupervised learning model employs a technique called clustering. The model finds data points that demarcate natural groupings.</p> <p>Clustering differs from classification because the categories aren’t defined by you.</p> <h3 id="reinforcement-learning">Reinforcement learning</h3> <p>Reinforcement learning models make predictions by getting rewards or penalties based on actions performed within an environment. A reinforcement learning system generates a policy that defines the best strategy for getting the most rewards.</p> <p>Reinforcement learning is used to train robots to perform tasks, like walking around a room, and software programs like AlphaGo to play the game of Go.</p> <h3 id="generative-ai">Generative AI</h3> <p>Generative AI is a class of models that creates content from user input.</p> <p>At a high-level, generative models learn patterns in data with the goal to produce new but similar data. Generative models are like the following:</p> <ul> <li>Comedians who learn to imitate others by observing people’s behaviors and style of speaking</li> <li>Artists who learn to paint in a particular style by studying lots of paintings in that style</li> <li>Cover bands that learn to sound like a specific music group by listening to lots of music by that group</li> </ul> <p>To produce unique and creative outputs, generative models are initially trained using an unsupervised approach, where the model learns to mimic the data it’s trained on. The model is sometimes trained further using supervised or reinforcement learning on specific data related to tasks the model might be asked to perform, for example, summarize an article or edit a photo.</p>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="ML"/><summary type="html"><![CDATA[ML is the process of training a piece of software, called a model, to make useful predictions or generate content (like text, images, audio, or video) from data.]]></summary></entry><entry><title type="html">Linear Regression</title><link href="https://benwzj.github.io/blog/2025/linear-regression/" rel="alternate" type="text/html" title="Linear Regression"/><published>2025-05-06T00:00:00+00:00</published><updated>2025-05-06T00:00:00+00:00</updated><id>https://benwzj.github.io/blog/2025/linear-regression</id><content type="html" xml:base="https://benwzj.github.io/blog/2025/linear-regression/"><![CDATA[<h2 id="what-is-linear-regression">What is Linear Regression</h2> <p>Training data to form a model, simply say, it is to find the bias and weights among the data. linear regression is one of the methods that find the relationship between features and a label to get the bias and weights.</p> <figure> <picture> <img src="/assets/img/car-data-points-with-model.png" class="img-fluid rounded z-depth-1" width="80%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>During training, the model calculates the <strong>weight</strong> and <strong>bias</strong> that produce the best model.</p> <figure> <picture> <img src="/assets/img/linear-regression-equation.png" class="img-fluid rounded z-depth-1" width="80%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="loss">Loss</h2> <p>Loss is a numerical metric that describes how wrong a model’s predictions are. Loss measures the distance between the model’s predictions and the actual labels. The goal of training a model is to minimize the loss, reducing it to its lowest possible value.</p> <figure> <picture> <img src="/assets/img/loss-lines.png" class="img-fluid rounded z-depth-1" width="80%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>The two most common methods to remove the sign are the following:</p> <ul> <li>Take the absolute value of the difference between the actual value and the prediction.</li> <li>Square the difference between the actual value and the prediction.</li> </ul> <p>There are four main types of loss:</p> <ul> <li><strong>L1 loss</strong>: The sum of the absolute values of the difference between the predicted values and the actual values.</li> <li><strong>Mean absolute error (MAE)</strong>: The average of L1 losses across a set of examples.</li> <li><strong>L2 loss</strong>: The sum of the squared difference between the predicted values and the actual values.</li> <li><strong>Mean squared error (MSE)</strong>: The average of L2 losses across a set of examples.</li> </ul> <h3 id="choosing-a-loss">Choosing a loss</h3> <p>In training, model will try to get the best bias and weights according to the LOSS. So choosing a loss is matter.</p> <p>When choosing the best loss function, also consider how you want the model to treat outliers. The outliers are closer to the model trained with MSE than to the model trained with MAE.</p> <figure> <picture> <img src="/assets/img/model-mse.png" class="img-fluid rounded z-depth-1" width="80%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>A model trained with MSE moves the model closer to the outliers.</p> <figure> <picture> <img src="/assets/img/model-mae.png" class="img-fluid rounded z-depth-1" width="80%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>A model trained with MAE is farther from the outliers.</p> <h2 id="gradient-descent">Gradient descent</h2> <p>Gradient descent is an iterative process that finds the best weights and bias that minimize the loss.</p> <p>Gradient descent is a <strong>mathematical technique</strong> that iteratively finds the weights and bias that produce the model with the lowest loss. Gradient descent finds the best weight and bias by repeating the following process for a number of user-defined iterations.</p> <p>The model begins training with randomized weights and biases near zero, and then repeats the following steps:</p> <ul> <li>Calculate the loss with the current weight and bias.</li> <li>Determine the direction to move the weights and bias that reduce loss.</li> <li>Move the weight and bias values a small amount in the direction that reduces loss.</li> <li>Return to step one and repeat the process until the model can’t reduce the loss any further.</li> </ul> <p>This is typical loss curve, Loss is on the y-axis and iterations are on the x-axis:</p> <figure> <picture> <img src="/assets/img/loss-convergence.png" class="img-fluid rounded z-depth-1" width="80%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Loss surface showing the weight and bias values that produce the lowest loss.</p> <figure> <picture> <img src="/assets/img/loss-surface-points.png" class="img-fluid rounded z-depth-1" width="80%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="hyperparameters">Hyperparameters</h2> <p>Hyperparameters are variables that control different aspects of training. Three common hyperparameters are:</p> <ul> <li>Learning rate</li> <li>Batch size</li> <li>Epochs</li> </ul> <p>In contrast, parameters are the variables, like the weights and bias, that are part of the model itself. In other words, hyperparameters are values that you control; parameters are values that the model calculates during training.</p> <h3 id="learning-rate">Learning rate</h3> <p>The learning rate determines the magnitude of the changes to make to the weights and bias during each step of the gradient descent process.</p> <p>The model multiplies the gradient by the learning rate to determine the model’s parameters (weight and bias values) for the next iteration. For example, if the <strong>gradient’s magnitude</strong> is 2.5 and the learning rate is 0.01, then the model will change the parameter by 0.025.</p> <p>Learning rate is a floating point number you set that influences how quickly the model converges.</p> <p>The ideal learning rate helps the model to converge within a reasonable number of iterations.</p> <p>What do it means when Learning Rate is 1? A learning rate of 1 means that the model updates its weights by the full amount of the calculated gradient. This almost inevitably leads to highly unstable training and the model failing to converge to a good solution.</p> <h3 id="batch-size">Batch size</h3> <p>Batch size is a hyperparameter that refers to the number of examples the model processes before updating its weights and bias.</p> <p>You might think that the model should do Full Batch, means calculating the loss for every example in the dataset before updating the weights and bias. However, when a dataset contains hundreds of thousands or even millions of examples, using the full batch isn’t practical.</p> <p>Two common techniques to get the right gradient on average without needing to look at every example in the dataset before updating the weights and bias:</p> <ul> <li>Stochastic gradient descent (SGD): Stochastic gradient descent uses only a single example (a batch size of one) per iteration. The term “stochastic” indicates that the one example comprising each batch is chosen at random. (Note that using stochastic gradient descent can produce noise throughout the entire loss curve, not just near convergence.)</li> <li>Mini-batch stochastic gradient descent (mini-batch SGD): Mini-batch stochastic gradient descent is a compromise between full-batch and SGD. The model chooses the examples included in each batch at random, averages their gradients, and then updates the weights and bias once per iteration.</li> </ul> <h3 id="epochs">Epochs</h3> <p>During training, an epoch means that the model has processed every example in the training set once. For example, given a training set with 1,000 examples and a mini-batch size of 100 examples, it will take the model 10 iterations to complete one epoch.</p> <p>Training typically requires many epochs. In general, more epochs produces a better model, but also takes more time to train.</p> <p>Here is an example to tell the difference:</p> <ul> <li>Full batch: After the model looks at all the examples in the dataset. For instance, if a dataset contains 1,000 examples and the model trains for 20 epochs, the model updates the weights and bias 20 times, once per epoch.</li> <li>Stochastic gradient descent: After the model looks at a single example from the dataset. For instance, if a dataset contains 1,000 examples and trains for 20 epochs, the model updates the weights and bias 20,000 times.</li> <li>Mini-batch stochastic gradient descent: After the model looks at the examples in each batch. For instance, if a dataset contains 1,000 examples, and the batch size is 100, and the model trains for 20 epochs, the model updates the weights and bias 200 times.</li> </ul> <h2 id="generate-a-correlation-matrix">Generate a correlation matrix</h2> <p>An important part of machine learning is determining which features correlate with the label. you can use a correlation matrix to identify features whose values correlate well with the label.</p> <p>Correlation values have the following meanings:</p> <ul> <li>1.0: perfect positive correlation; that is, when one attribute rises, the other attribute rises.</li> <li>-1.0: perfect negative correlation; that is, when one attribute rises, the other attribute falls.</li> <li>0.0: no correlation; the two columns are not linearly related. In general, the higher the absolute value of a correlation value, the greater its predictive power.</li> </ul> <p>dataframe can provide such function: <code class="language-plaintext highlighter-rouge">training_df.corr(numeric_only = True)</code></p> <h2 id="visualize-relationships-in-dataset">Visualize relationships in dataset</h2> <p>dataframe provide such function: <code class="language-plaintext highlighter-rouge">sns.pairplot(training_df, x_vars=["FARE", "TRIP_MILES", "TRIP_SECONDS"], y_vars=["FARE", "TRIP_MILES", "TRIP_SECONDS"])</code></p> <h2 id="references">References</h2>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="ML"/><summary type="html"><![CDATA[What is Linear Regression]]></summary></entry><entry><title type="html">What is Transformer</title><link href="https://benwzj.github.io/blog/2025/transformer/" rel="alternate" type="text/html" title="What is Transformer"/><published>2025-05-05T00:00:00+00:00</published><updated>2025-05-05T00:00:00+00:00</updated><id>https://benwzj.github.io/blog/2025/transformer</id><content type="html" xml:base="https://benwzj.github.io/blog/2025/transformer/"><![CDATA[<h2 id="what-is-transformer">What is Transformer</h2> <p>Transformer is a type of neural network architecture.</p> <ul> <li>Transformers were initially designed for translation, superseded RNN.</li> <li>Unlike traditional recurrent or convolutional models that process data sequentially, the Transformer leverages a mechanism called <strong>self-attention</strong> to process all input data simultaneously. This allows for much greater parallelization, leading to faster training and the ability to handle longer sequences of data effectively.</li> <li>Transformers are widely used in various fields, including natural language processing (NLP) for tasks like translation, text generation, and question answering, as well as computer vision.</li> <li>In essence, transformer models have revolutionized the way we process and understand sequential data by leveraging the power of attention and parallel processing.</li> <li>Like GPT(Generative Pre-trained Transformer), BERT(Bidirectional Encoder Representations from Transformers), they are based on Transformers.</li> <li>Self-Attention and Positional Encoding are the main innovations.</li> </ul> <h2 id="key-concepts">Key Concepts</h2> <ul> <li>Self-Attention: The core innovation of Transformers. It allows the model to weigh the importance of different parts of the input when generating an output. For example, in a sentence, the word “it” might refer to different things depending on the context. Self-attention helps the model understand these relationships. It does this by calculating relationships between every word in a sequence and every other word, creating a weighted representation of the input.</li> <li>Attention Mechanism: A more general concept that allows the model to focus on specific parts of the input when generating an output. Self-attention is a specific type of attention.</li> <li>Encoder-Decoder Architecture: Many Transformers follow this structure. The encoder processes the input sequence and generates a contextualized representation. The decoder then uses this representation to generate the output sequence.</li> <li>Parallelization: Unlike recurrent networks that process input sequentially, Transformers can process all input tokens simultaneously, significantly speeding up training.</li> <li>Positional Encoding: Because Transformers don’t process sequentially, positional information of words in a sentence is lost. Positional encodings are added to the input embeddings to provide information about the position of each word.</li> <li>Feedforward Networks: Fully connected layers within each encoder and decoder layer that further process the information from the attention mechanism.</li> <li>Layer Normalization: A normalization technique used to stabilize training and improve performance.</li> </ul> <h2 id="how-a-transformer-works-simplified">How a Transformer works (simplified)</h2> <ul> <li>Input Embedding: The input sequence (e.g., a sentence) is converted into numerical representations called embeddings.</li> <li>Positional Encoding: Positional information is added to the embeddings.</li> <li>Encoder: Multiple encoder layers process the embeddings using self-attention and feedforward networks. Each encoder layer produces a set of encoded representations.</li> <li>Decoder: The decoder takes the encoded representations from the encoder and, using self-attention and feedforward networks, generates the output sequence (e.g., a translation, a summary, or the next word in a sentence). The decoder also uses attention mechanisms to focus on relevant parts of the encoded input.</li> <li>Output: The final decoder layer produces the output.</li> </ul> <h2 id="why-are-transformers-important">Why are Transformers important</h2> <p>Improved Performance: They have achieved state-of-the-art results in various NLP tasks. Parallelization: They train much faster than recurrent models. Handling Long Sequences: They can effectively process long sequences of data.</p> <h2 id="rnn">RNN</h2> <p>A recurrent neural network (RNN) is a type of neural network architecture specifically designed to process <strong>sequential</strong> data. it have many problems. Like:</p> <ul> <li>it struggle to learn long-range dependencies.</li> <li>Because sequential, it can’t be parallelized training. it is very slow.</li> </ul> <p>RNNs have been largely superseded by Transformer networks.</p>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="Transformer"/><summary type="html"><![CDATA[What is Transformer]]></summary></entry><entry><title type="html">Diffusion Model Concepts</title><link href="https://benwzj.github.io/blog/2025/diffusion-model/" rel="alternate" type="text/html" title="Diffusion Model Concepts"/><published>2025-05-04T00:00:00+00:00</published><updated>2025-05-04T00:00:00+00:00</updated><id>https://benwzj.github.io/blog/2025/diffusion-model</id><content type="html" xml:base="https://benwzj.github.io/blog/2025/diffusion-model/"><![CDATA[<h2 id="what-is-diffusion-model">what is Diffusion Model</h2> <p>A diffusion model is a type of generative model, meaning it’s used to create new data instances that resemble the data it was trained on.</p> <p>There are two Steps:</p> <ul> <li>Model need to understand your input: it can be text or image. How?</li> <li>When Model know your meaning, it need to craft the image. How?</li> </ul> <p>At a high level, a diffusion model is a type of deep neural network what learn to add noise to a picture and then learn how to reverse that process to recontruct a clear image.</p> <p>The logic like this: the model have been trained lots of images, and store them as noises and embedding. when it is ask to generate a specific image, it can retrive noises and reverse back to image.</p> <h2 id="main-concepts">Main Concepts</h2> <h3 id="forward-diffusion-or-diffusion-process">Forward Diffusion (or Diffusion Process):</h3> <p>This process gradually adds Gaussian noise to a <strong>training image</strong> over a series of small timesteps until the image becomes pure noise, losing all its original information. This is a Markov chain process, meaning each step only depends on the previous step.</p> <h3 id="reverse-diffusion-or-denoising-process">Reverse Diffusion (or Denoising Process):</h3> <p>This is the heart of the diffusion model. It learns to reverse the diffusion process, effectively removing noise step-by-step to reconstruct the original image (or generate a new image based on a prompt). The model learns the conditional probability distribution of the image at each timestep, given the noisy image at the next timestep.</p> <h3 id="markov-chain">Markov Chain:</h3> <p>A sequence of events where the probability of each event depends only on the state attained in the previous event. Diffusion models use this concept for both the forward and reverse processes.</p> <h3 id="gaussian-noise">Gaussian Noise:</h3> <p>A type of random noise that follows a normal distribution (bell curve).</p> <h2 id="how-it-works">How it works</h2> <h3 id="training">Training:</h3> <p>The model is trained on a large dataset of images. During training, it learns how noise is added at each timestep in the forward diffusion process. Crucially, it also learns how to reverse this process, effectively denoising.</p> <h3 id="inference-generating-images">Inference (Generating Images):</h3> <p>Start with pure noise. Iteratively apply the reverse diffusion process, guided by the text prompt (often encoded by an LLM). At each timestep, the model predicts the slightly less noisy image based on the current noisy image and the text embedding. Repeat this process until a clean image is generated.</p> <h2 id="examples-of-diffusion-models">Examples of Diffusion Models</h2> <p>Stable Diffusion DALL-E 2 Imagen</p>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="Diffusion"/><summary type="html"><![CDATA[what is Diffusion Model]]></summary></entry><entry><title type="html">Google AI Studio</title><link href="https://benwzj.github.io/blog/2025/google-ai-studio/" rel="alternate" type="text/html" title="Google AI Studio"/><published>2025-03-26T00:00:00+00:00</published><updated>2025-03-26T00:00:00+00:00</updated><id>https://benwzj.github.io/blog/2025/google-ai-studio</id><content type="html" xml:base="https://benwzj.github.io/blog/2025/google-ai-studio/"><![CDATA[<h2 id="what-is-function-calling">What is Function Calling</h2> <p>Function calling lets you connect models to external tools and APIs. Instead of generating text responses, the model understands when to call specific functions and provides the necessary parameters to execute real-world actions. This allows the model to act as a bridge between natural language and real-world actions and data. Function calling has 3 primary use cases:</p> <ul> <li>Augment Knowledge: Access information from external sources like databases, APIs, and knowledge bases.</li> <li>Extend Capabilities: Use external tools to perform computations and extend the limitations of the model, such as using a calculator or creating charts.</li> <li>Take Actions: Interact with external systems using APIs, such as scheduling appointments, creating invoices, sending emails, or controlling smart home devices</li> </ul>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="Prompt"/><summary type="html"><![CDATA[What is Function Calling]]></summary></entry><entry><title type="html">AI Agent</title><link href="https://benwzj.github.io/blog/2025/ai-agent/" rel="alternate" type="text/html" title="AI Agent"/><published>2025-03-05T00:00:00+00:00</published><updated>2025-03-05T00:00:00+00:00</updated><id>https://benwzj.github.io/blog/2025/ai-agent</id><content type="html" xml:base="https://benwzj.github.io/blog/2025/ai-agent/"><![CDATA[<h2 id="what-is-ai-agent">What is AI Agent</h2> <p>AI Agent is like an expert designed to help with tasks and answer questions. E.g. coding agent, marketing agent, learning agent or just a friend.</p> <p>An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system by designing its workflow and utilizing available tools.</p> <p>AI agents can encompass a wide range of functionalities beyond natural language processing including decision-making, problem-solving, interacting with external environments and executing actions.</p> <p>AI agents can encompass a wide range of functionalities beyond natural language processing including decision-making, problem-solving, interacting with external environments and executing actions.</p> <h2 id="what-is-not-ai-agent">What is NOT AI agent?</h2> <p>When you are using prompt to ask ChatGPT directly, for example, ask it ‘please write out an essay on Topic XXX from start to end in one go’. This is not AI Agent. Probably charGPT still give you some information, but They are possibly not the thing you are looking for. For the complicated topic, Agentic workflow can significantly improve the result. Basically, it is breaking the topic into many steps, it also include iteration, revise, etc.</p> <h3 id="important-terms">Important terms</h3> <ul> <li>circulation</li> <li>external tools</li> </ul> <p>LLM BERT Reflection</p> <p>OpenAI - GPT, DALL·E, Sora</p> <p>Gemini - formerly known as Bard, is a generative artificial intelligence chatbot developed by Google. Based on the large language model (LLM) of the same name, it was launched in 2023 in response to the rise of OpenAI’s ChatGPT. It was previously based on the LaMDA and PaLM LLMs.</p> <p>Anthropic - Claude xAI - Grok Qwen DeepSeek Llama</p>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><summary type="html"><![CDATA[What is AI Agent]]></summary></entry><entry><title type="html">Prompt for LLM</title><link href="https://benwzj.github.io/blog/2025/prompting/" rel="alternate" type="text/html" title="Prompt for LLM"/><published>2025-03-05T00:00:00+00:00</published><updated>2025-03-05T00:00:00+00:00</updated><id>https://benwzj.github.io/blog/2025/prompting</id><content type="html" xml:base="https://benwzj.github.io/blog/2025/prompting/"><![CDATA[<p>AI is a Revolution! Many part of activities in the society will shift to AI. Now Prompting is obviously a biggest capability, skill to stay informed.</p> <blockquote> <p>Prompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts is an essential part of ensuring accurate, high quality responses from a language model.</p> </blockquote> <h2 id="prompt-design-strategies">Prompt design strategies</h2> <p>Here list some concepts:</p> <h3 id="clear-and-specific-instructions">Clear and Specific instructions</h3> <ul> <li>Give the models instructions on what to do.</li> <li>Make the instructions clear and specific.</li> <li>Specify any constraints or formatting requirements for the output.</li> </ul> <h3 id="include-few-shot-examples">Include Few-shot Examples</h3> <p>We recommend to always include few-shot examples in your prompts. Prompts without few-shot examples are likely to be less effective. In fact, you can remove instructions from your prompt if your examples are clear enough in showing the task at hand.</p> <h3 id="add-contextual-information">Add contextual information</h3> <ul> <li>Include information (context) in the prompt that you want the model to use when generating a response.</li> <li>Give the model instructions on how to use the contextual information.</li> </ul> <h3 id="add-prefixes">Add prefixes</h3> <p>A prefix is a word or phrase that you add to the prompt content that can serve several purposes, depending on where you put the prefix:</p> <ul> <li>Input prefix: Adding a prefix to the input signals semantically meaningful parts of the input to the model. For example, the prefixes “English:” and “French:” demarcate two different languages.</li> <li>Output prefix: Even though the output is generated by the model, you can add a prefix for the output in the prompt. The output prefix gives the model information about what’s expected as a response. For example, the output prefix “JSON:” signals to the model that the output should be in JSON format.</li> <li>Example prefix: In few-shot prompts, adding prefixes to the examples provides labels that the model can use when generating the output, which makes it easier to parse output content.</li> </ul> <h3 id="let-the-model-complete-partial-input">Let the model complete partial input</h3> <ul> <li>If you give the model a partial input, the model completes that input based on any available examples or context in the prompt.</li> <li>Having the model complete an input may sometimes be easier than describing the task in natural language.</li> <li>Adding a partial answer to a prompt can guide the model to follow a desired pattern or format.</li> </ul> <h3 id="break-down-prompts-into-simple-components">Break down prompts into simple components</h3> <ul> <li>Break down complex instructions into a prompt for each instruction and decide which prompt to apply based on the user’s input.</li> <li>Break down multiple sequential steps into separate prompts and chain them such that the output on the preceding prompt becomes the input of the following prompt.</li> <li>Break down parallel tasks and aggregate the responses to produce the final output.</li> </ul> <h3 id="experiment-with-different-parameter-values">Experiment with different parameter values</h3> <p>There are some common parameters:</p> <ul> <li>Max output tokens: Maximum number of tokens that can be generated in the response.</li> <li>Temperature</li> <li>Top-K</li> <li>Top-P</li> </ul> <p>Temperature, Top-K and Top-P change how the model selects tokens for output.</p> <h3 id="prompt-iteration-strategies">Prompt iteration strategies</h3> <p>Using different words or phrasing in your prompts often yields different responses from the model even though they all mean the same thing.</p> <h3 id="fallback-responses">Fallback responses</h3> <p>A fallback response is a response returned by the model when either the prompt or the response triggers a safety filter. An example of a fallback response is “I’m not able to help with that, as I’m only a language model.”</p> <p>If the model responds with a fallback response, try increasing the temperature.</p> <h3 id="things-to-avoid">Things to avoid</h3> <ul> <li>Avoid relying on models to generate factual information.</li> <li>Use with care on math and logic problems.</li> </ul> <h2 id="useful-tips-for-prompt">Useful tips for Prompt</h2> <ul> <li>Use persona, the role of AI itself. For example, ‘act as anime expert to suggest a anime gife for my friend birthday gift’.</li> <li>You can order the data into a table.</li> <li>If you can provide context, references, that will be better.</li> <li>Do Promting with one word: TCREI (Task Context Refercences Evaluate Iterate).</li> <li>Iteration have some tips (RSTI): <ul> <li>Revisit the prompt framework.</li> <li>Separate prompt into shorter ones.</li> <li>Trying different phrasing or switching to an analogous task.</li> <li>Introduce constrain</li> </ul> </li> <li>Prompt chaining <ul> <li>Chain of thought prompting</li> <li>Tree of thought prompting</li> </ul> </li> <li>if you stuck with prompt somewhere, you can ask AI to help with Prompt for you. This is call meta prompting.</li> </ul> <h3 id="example">Example</h3> <figure> <picture> <img src="/assets/img/prompt-example.png" class="img-fluid rounded z-depth-1" width="80%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="file-prompting-strategies">File prompting strategies</h2> <p>Like Gemini, ChatGPT, Clause models, Most LLMs are built to handle various types of input data, including text,files, images, and audio.</p> <p>AI can understand files, images, videos just like you! It can be even better than you.</p> <p>When you do this:</p> <figure> <picture> <img src="/assets/img/timetable.png" class="img-fluid rounded z-depth-1" width="60%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><code class="language-plaintext highlighter-rouge">Parse the time and city from the airport board shown in this image into a list.</code> AI can response this:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- 10:50 Moscow
- 11:05 Edinburgh
- 11:05 London
- 11:10 Bucharest
- 11:30 Kiev
- 11:35 Dublin
- 11:45 East Midlands
- 12:15 Sofia
- 12:30 London
- 12:30 Newcastle
- 12:40 St Petersburg
- 12:40 London
- 12:45 Manchester
</code></pre></div></div> <h2 id="imagen-prompt-guide">Imagen prompt guide</h2>]]></content><author><name></name></author><category term="AI"/><category term="AI"/><category term="Prompt"/><summary type="html"><![CDATA[AI is a Revolution! Many part of activities in the society will shift to AI. Now Prompting is obviously a biggest capability, skill to stay informed.]]></summary></entry><entry><title type="html">NoSQL Database Overview</title><link href="https://benwzj.github.io/blog/2025/nosql/" rel="alternate" type="text/html" title="NoSQL Database Overview"/><published>2025-02-13T00:00:00+00:00</published><updated>2025-02-13T00:00:00+00:00</updated><id>https://benwzj.github.io/blog/2025/nosql</id><content type="html" xml:base="https://benwzj.github.io/blog/2025/nosql/"><![CDATA[<h2 id="what-is-nosql">What is NoSQL</h2> <p>When talking about NoSQL database, there are many concepts are based on or compare to SQL database concepts. SQL database have much longer history and it is very mature.</p> <p>Here are some points for NoSQL database:</p> <ul> <li>NoSQL databases store data differently than relational tables.</li> <li>It come out mostly because storage is getting cheaper.</li> <li>It store data in a more natural and flexible way than relational tables.</li> <li>The main types are document, key-value, wide-column, and graph.</li> <li>You can say it is Schemaless Database.</li> <li>They are BASE compliance. And some can be ACID compliance as well.</li> </ul> <h3 id="brief-history-of-nosql-databases">Brief history of NoSQL databases</h3> <p>NoSQL databases emerged in the late 2000s as <strong>the cost of storage dramatically decreased</strong>. Gone were the days of needing to create a complex, difficult-to-manage data model in order to avoid data duplication. NoSQL databases optimized for developer productivity.</p> <p>In the early 2000s, a paper published by Google on BigTable, the wide-column database, explored the wide range of possibilities for a distributed storage system. 2009 saw a major rise in NoSQL databases, with two key document-oriented databases, MongoDB and CouchDB, coming into the picture.</p> <h3 id="features">Features</h3> <p>At a high level, NoSQL databases typically have the following features:</p> <ul> <li>Distributed computing</li> <li>Easy to scale out</li> <li>Flexible schemas and rich query language</li> <li>Ease of use for developers</li> <li>Partition tolerance</li> <li>High availability</li> </ul> <h2 id="base-compliance">BASE compliance</h2> <p>NoSQL databases are BASE compliant, i.e., (Basic Availability Soft state Eventual consistency).</p> <ul> <li>Basic availability refers to the ability of the system to tolerate a partial failure (like a loss of a node).</li> <li>Soft state means that the system allows temporary inconsistencies before eventually achieving consistency automatically over time.</li> </ul> <p>BASE compliance ensures high availability, faster data processing, scalability, and flexibility. However, MongoDB can also be configured to provide multi-document <strong>ACID compliance</strong>(Atomicity, Consistency, Isolation, and Durability).</p> <h2 id="partition">Partition</h2> <p>In NoSQL databases, a partition (also known as a shard in MongoDB) is a way to divide the database into smaller, more manageable pieces. Each partition contains a subset of the data and is managed by a specific server or set of servers. This approach helps in distributing the data across multiple servers, which can improve performance, scalability, and fault tolerance.</p> <p>In MongoDB, a sharded database is an example of a partitioned database. Here, the data is divided into shards, and each shard is managed by a set of servers. Each shard has a primary server that handles all the writes and reads, and secondary servers that replicate the data for redundancy and failover.</p> <h3 id="partition-key">Partition Key</h3> <p>The partition key (or shard key) is used to determine how the data is distributed across the shards. This key is crucial for ensuring an even distribution of data and optimizing query performance.</p> <p>For example, in a MongoDB sharded cluster, each shard maintains exclusive control of its partition of the data. If the primary server of a shard fails, one of the secondary servers is automatically elected to become the primary, ensuring high availability.</p> <p>In summary, a partition in NoSQL databases is a method to distribute data across multiple servers to enhance performance, scalability, and reliability. The partition key is essential for distributing data across the cluster and ensuring efficient query performance.</p> <p>When selecting a shard key, it’s important to consider the following:</p> <ul> <li>The shard key should be chosen to ensure an even distribution of data across the shards.</li> <li>The shard key should support the most common query patterns to optimize performance.</li> <li>The shard key should be immutable if it includes the _id field.</li> </ul> <h2 id="common-misconception">Common Misconception</h2> <h3 id="nosql-databases-dont-store-relationship-data-well">NoSQL databases don’t store relationship data well</h3> <p>NoSQL databases can store relationship data — they just store it differently than relational databases do. In fact, many find modeling relationship data in NoSQL databases to be easier than in relational databases because related data doesn’t have to be split between tables. NoSQL data models allow related data to be nested within a single data structure.</p> <h3 id="nosql-databases-dont-support-acid-transactions">NoSQL databases don’t support ACID transactions</h3> <p>Some NoSQL databases, like MongoDB, do, in fact, support ACID transactions.</p> <h2 id="schemaless-database">Schemaless Database</h2> <p>Schemaless database is compare to traditional SQL database. A schemaless database, like MongoDB, does not have these up-front constraints, mapping to a more ‘natural’ database. Any data, formatted or not, can be stored in a non-tabular NoSQL type of database.</p> <h3 id="how-does-a-schemaless-database-work">How does a schemaless database work?</h3> <p>In schemaless databases, information is stored in JSON-style documents which can have varying sets of fields with different data types for each field. So, a collection could look like this:</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">    </span><span class="p">{</span><span class="w"> 
        </span><span class="err">name</span><span class="w"> </span><span class="err">:</span><span class="w"> </span><span class="err">“Joe”</span><span class="p">,</span><span class="w"> </span><span class="err">age</span><span class="w"> </span><span class="err">:</span><span class="w"> </span><span class="mi">30</span><span class="p">,</span><span class="w"> </span><span class="err">interests</span><span class="w"> </span><span class="err">:</span><span class="w"> </span><span class="err">‘football’</span><span class="w"> </span><span class="p">}</span><span class="w">
    </span><span class="p">{</span><span class="w"> 
        </span><span class="err">name</span><span class="w"> </span><span class="err">:</span><span class="w"> </span><span class="err">“Kate”</span><span class="p">,</span><span class="w"> </span><span class="err">age</span><span class="w"> </span><span class="err">:</span><span class="w"> </span><span class="mi">25</span><span class="w"> </span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>As you can see, the data itself normally has a fairly consistent structure. With the schemaless MongoDB database, there is some additional structure — the system namespace contains an explicit list of collections and indexes. Collections may be implicitly or explicitly created — indexes must be explicitly declared.</p> <h2 id="mongodb">MongoDB</h2> <p>The way of using MongoDB is similar to SQL database like MySql. It provide MongoDB Compass to operate your database. MongoDB Shell can run it’s APIs just like running SQL for you SQLDB.</p> <h3 id="terms">Terms</h3> <ul> <li>MongoDB Compass: It is a software which is database window interface, something like ‘MySQLWorkbench’.</li> <li>MongoDB Shell (mongosh): Can run commands, Like <code class="language-plaintext highlighter-rouge">db.movies.find( { "title": "Titanic" } )</code>.</li> <li>Collection: similar to table in SQL DB</li> <li>Documents: similar to row in SQL DB</li> <li>Field: similar to column in SQL DB</li> <li>Views: A MongoDB view is a read-only queryable object whose contents are defined by an aggregation pipeline on other collections or views.</li> <li>Query APIs: comprises two ways to query data in MongoDB: <ul> <li><code class="language-plaintext highlighter-rouge">find()</code> Operations</li> <li>Aggregation pipelines</li> </ul> </li> <li>CRUD APIs: like <code class="language-plaintext highlighter-rouge">updateOne(), updateMany() insertOne(), deleteOne(), find()</code>, etc.</li> <li>Triggers: support Triggers.</li> </ul> <h3 id="find">find()</h3> <p>When you get to know how to use <code class="language-plaintext highlighter-rouge">find()</code>, other CRUD APIs are similar.</p> <p>Use <code class="language-plaintext highlighter-rouge">find</code> command: <code class="language-plaintext highlighter-rouge">db.movies.find( { "title": "Titanic" } )</code>.</p> <ul> <li>You can ‘Project Fields’ for your return by using ‘Project Selectors’.</li> <li>You can filter document for your return by using ‘Query Selectors’.</li> <li>You can sort, limit return.</li> </ul> <h4 id="matches-any-of-the-values-specified-in-an-array-or-not-in-array">Matches any of the values specified in an array or NOT in array</h4> <p><code class="language-plaintext highlighter-rouge">$in</code> and <code class="language-plaintext highlighter-rouge">$nin</code></p> <p>For example: <code class="language-plaintext highlighter-rouge">db.movies.find( { rated: { $in: [ "PG", "PG-13" ] } } )</code> This operation corresponds to the following SQL statement: <code class="language-plaintext highlighter-rouge">SELECT * FROM movies WHERE rated in ("PG", "PG-13")</code></p> <h4 id="matches-values-that-are-equal-or-greater-or-less-to-a-specified-value">Matches values that are equal or greater or less to a specified value.</h4> <ul> <li><code class="language-plaintext highlighter-rouge">$eq</code></li> <li><code class="language-plaintext highlighter-rouge">$gt</code></li> <li><code class="language-plaintext highlighter-rouge">$gte</code></li> <li><code class="language-plaintext highlighter-rouge">$lt</code></li> <li><code class="language-plaintext highlighter-rouge">$lte</code></li> <li><code class="language-plaintext highlighter-rouge">$ne</code></li> </ul> <p>For example: <code class="language-plaintext highlighter-rouge">db.movies.find( { countries: "Mexico","imdb.rating": { $gte: 7 } } )</code></p> <h4 id="logical-operators">Logical Operators</h4> <ul> <li><code class="language-plaintext highlighter-rouge">$and</code></li> <li><code class="language-plaintext highlighter-rouge">$or</code></li> </ul> <p>For example: <code class="language-plaintext highlighter-rouge">db.movies.find( { $and: [ {countries: "Mexico"} , {"imdb.rating": { $gte: 7 }} ] } )</code></p> <h4 id="count">count()</h4> <ul> <li>Returns the count of documents that would match a find() query for the collection or view.</li> <li>The db.collection.count() method does not perform the find() operation but instead counts and returns the number of results that match a query.</li> <li><code class="language-plaintext highlighter-rouge">db.collection.count(query, options)</code></li> <li>Example: <code class="language-plaintext highlighter-rouge">db.collection.find( { a: 5, b: 5 } ).count()</code></li> </ul> <h3 id="aggregation">Aggregation</h3> <p>Aggregation operations process multiple documents and return computed results. You can use aggregation operations to:</p> <ul> <li>Group values from multiple documents together.</li> <li>Perform operations on the grouped data to return a single result.</li> <li>Analyze data changes over time.</li> </ul> <h4 id="aggregate-pipelines-example">Aggregate Pipelines Example:</h4> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>db.orders.aggregate( [
   // Stage 1: Filter pizza order documents by pizza size
   {
      $match: { size: "medium" }
   },
   // Stage 2: Group remaining documents by pizza name and calculate total quantity
   {
      $group: { _id: "$name", totalQuantity: { $sum: "$quantity" } }
   }
] )
</code></pre></div></div> <h5 id="the-match-stage">The <code class="language-plaintext highlighter-rouge">$match</code> stage:</h5> <p>Filters the pizza order documents to pizzas with a size of medium. Passes the remaining documents to the $group stage.</p> <h5 id="the-group-stage">The <code class="language-plaintext highlighter-rouge">$group</code> stage:</h5> <p>Groups the remaining documents by pizza name. Uses <code class="language-plaintext highlighter-rouge">$sum</code> to calculate the total order quantity for each pizza name. The total is stored in the totalQuantity field returned by the aggregation pipeline.</p> <h4 id="what-is-aggregate-pipelines">What is Aggregate Pipelines</h4> <p>An aggregation pipeline consists of one or more stages that process documents:</p> <ul> <li>Each stage performs an operation on the input documents. For example, a stage can filter documents, group documents, and calculate values.</li> <li>The documents that are output from a stage are passed to the next stage.</li> <li>An aggregation pipeline can return results for groups of documents. For example, return the total, average, maximum, and minimum values.</li> </ul> <h4 id="aggregate-pipelines-stages">Aggregate Pipelines Stages</h4> <p>Each States have a name, like <code class="language-plaintext highlighter-rouge">$match</code>, <code class="language-plaintext highlighter-rouge">$group</code>, <code class="language-plaintext highlighter-rouge">$sort</code> etc.</p> <h3 id="distinct">distinct()</h3> <p><code class="language-plaintext highlighter-rouge">db.collection.distinct()</code> Finds the distinct values for a specified field across a single collection or view and returns the results in an array.</p> <p>This can help you to understand the data in the collection.</p> <h3 id="indexes">Indexes</h3> <p>Indexes support the efficient execution of queries in MongoDB.</p> <blockquote> <p>Concept Index in NoSQL is different from SQL database. In MongoDB, developer usually will create many indexes to improve queries. And when you create indexes MongoDB will product index size for them.</p> </blockquote> <h4 id="index-features">Index Features</h4> <ul> <li>Although indexes improve query performance, adding an index has negative performance impact for write operations.</li> <li>Indexes don’t have to be unique.</li> <li>Compound index is common.</li> <li>Indexes store a small portion of the collection’s data set in an easy to traverse form.</li> <li>The index stores the value of a specific field or set of fields, ordered by the value of the field.</li> <li>You can easily create indexex for a collection.</li> <li>TTL indexes are special single-field indexes that MongoDB can use to automatically remove documents from a collection after a certain amount of time or at a specific clock time.</li> </ul> <h4 id="compound-indexing-strategies-the-esr-equality-sort-range-rule">Compound Indexing Strategies: The ESR (Equality, Sort, Range) Rule</h4> <p>In order to improve query performance, There is a rule when using index! It is ESR Rule.</p> <p>Understand ESR Rule:</p> <p>For example, In a CAR collection, your query is: <code class="language-plaintext highlighter-rouge">db.cars.find( { model: "Cordoba" } )</code> And you want it to be sorted by model: <code class="language-plaintext highlighter-rouge">db.cars.find( { manufacturer: "GM" } ).sort( { model: 1 } )</code> And also you have some range filter: like cost more than $20000: <code class="language-plaintext highlighter-rouge">db.cars.find( { manufacturer: 'Ford', cost: { $gt:10000 } } ).sort( { model: 1 } )</code></p> <blockquote> <p>What is ‘Range’? Range refer to Range query, Range filter. using <code class="language-plaintext highlighter-rouge">$gte</code> or <code class="language-plaintext highlighter-rouge">$lt</code> etc.</p> </blockquote> <p>Following the ESR rule, the optimal index for the example query is: <code class="language-plaintext highlighter-rouge">db.cars.createIndex( { manufacturer: 1, model: 1, cost: 1 } )</code></p> <h5 id="key-points-about-the-esr-rule">Key points about the ESR rule:</h5> <ul> <li>Equality first: When creating a compound index, the field that is most frequently used in equality comparisons (like filtering on a specific value) should be placed first.</li> <li>Sort next: Following the equality field, the field that is often used for sorting operations (like ordering results by a certain criteria) should be added to the index.</li> <li>Range last: Finally, if a range query is needed on a field (like finding values within a specific range), that field should be placed last in the compound index.</li> </ul> <h3 id="query-plan">Query Plan</h3> <p>MongoDB have Query Plan concept</p> <p>For any given query, the MongoDB query planner chooses and caches the most efficient query plan given the available indexes. To evaluate the efficiency of query plans, the query planner runs all candidate plans during a trial period. In general, the winning plan is the query plan that produces the most results during the trial period while performing the least amount of work.</p> <p>To view the query plan information for a given query, you can use: <code class="language-plaintext highlighter-rouge">db.collection.explain().find({manufacturer: 'Ford'})</code></p> <p>You can check your <code class="language-plaintext highlighter-rouge">Index</code> effection by view the <code class="language-plaintext highlighter-rouge">Query Plan</code>. For example, when you <code class="language-plaintext highlighter-rouge">find({manufacturer: 'Ford'})</code> before the create the <code class="language-plaintext highlighter-rouge">manufacturer</code> index, MongoDB is using <code class="language-plaintext highlighter-rouge">COLLSCAN</code>. But when you create the index, MonboDB is using <code class="language-plaintext highlighter-rouge">IXSCAN</code>.</p> <h3 id="data-types">Data types</h3> <ul> <li>Object ID − This datatype is used to store the document’s ID. Like: <code class="language-plaintext highlighter-rouge">_id = ObjectId()</code></li> <li>String − This is the most commonly used datatype to store the data. String in MongoDB must be UTF-8 valid.</li> <li>Array − This type is used to store arrays or list or multiple values into one key.</li> <li>Integer − This type is used to store a numerical value. Integer can be 32 bit or 64 bit depending upon your server.</li> <li>Boolean − This type is used to store a boolean (true/ false) value.</li> <li>Double − This type is used to store floating point values.</li> <li>Timestamp − ctimestamp. This can be handy for recording when a document has been modified or added.</li> <li>Object − This datatype is used for embedded documents.</li> <li>Null − This type is used to store a Null value.</li> <li>Date − This datatype is used to store the current date or time in UNIX time format. You can specify your own. Like <code class="language-plaintext highlighter-rouge">new Date(”2002-01-30”)</code></li> </ul> <h2 id="references">References</h2> <ul> <li><a href="https://www.mongodb.com/nosql-explained">mongoDB nosql-explained</a></li> <li><a href="https://www.mongodb.com/unstructured-data/schemaless">what is schemaless</a></li> </ul>]]></content><author><name></name></author><category term="Database"/><category term="Database"/><category term="SQL"/><summary type="html"><![CDATA[What is NoSQL]]></summary></entry></feed>